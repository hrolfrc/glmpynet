\documentclass[11pt, a4paper]{article}

% --- PREAMBLE: PACKAGES AND SETUP ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{booktabs} 
\usepackage{enumitem} 
\usepackage{hyperref} 
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}

% --- GEOMETRY ---
\geometry{a4paper, margin=1in}

% --- HYPERREF SETUP ---
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={bib-ami Documentation},
    pdfauthor={bib-ami Team},
}

% --- LISTINGS (CODE) SETUP ---
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegray},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}


% --- TITLE ---
\title{\textbf{bib-ami}: A Bibliography Integrity Manager \\ \large Part 3: Architecture \& Workflow}
\author{Documentation}
\date{\today}


% ==================================================================
% --- DOCUMENT START ---
% ==================================================================
\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Architecture \& Workflow}

This section explains how \texttt{bib-ami} works internally. It details the high-level architecture, the step-by-step data processing workflow, the core software components, and the structure of the final output. This provides a deeper understanding for users who wish to know how the tool achieves its results.

\subsection{High-Level Overview}

The \texttt{bib-ami} tool is designed as a modular, file-based pipeline. This architecture ensures that the process is both auditable and robust. Each major step in the workflow is a distinct phase that takes a file as input and produces a new file as output. This allows for easy inspection at each stage and enables the process to be resumed from the last successful checkpoint in case of failure.

The pipeline consists of four primary phases: Ingestion, Validation, Reconciliation, and Reporting.

\subsection{The Four-Phase Process}

These phases directly implement the guiding principles outlined in the previous section to transform a collection of source files into a clean, verified bibliography.

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Phase 1: Ingestion and Tagging} \\
    The workflow begins by reading all \texttt{.bib} files from the user-specified input directory. Each entry is parsed and assigned a unique internal ID. This ID ensures that every source record can be traced throughout the entire process, upholding the principle of \textit{Every Input Must Be Accounted For}. The result of this phase is a single, consolidated intermediate file (e.g., \texttt{01\_ingested.json}) containing all candidate references.

    \item \textbf{Phase 2: Validation and Canonicalization} \\
    This phase establishes the "ground truth" for each record. It iterates through every entry from the ingested file and queries an authoritative source (CrossRef) using the entry's title and author. 
    \begin{itemize}[leftmargin=*]
        \item If a DOI is found, it is added to the record as its canonical identifier.
        \item If a DOI already exists, it is validated against the API's result; any incorrect DOI is replaced.
    \end{itemize}
    This rigorously follows the principle of \textit{Authoritative Data Reigns Supreme}. The output is a new intermediate file (e.g., \texttt{02\_validated.json}) where each record is now enriched with a verified DOI and a validation status.

    \item \textbf{Phase 3: Reconciliation and Deduplication} \\
    Using the verified DOIs as the primary key, this phase identifies and merges duplicate records.
    \begin{itemize}[leftmargin=*]
        \item All entries sharing the same DOI are grouped together.
        \item For each group, a single "golden record" is created, with its core metadata populated from the authoritative CrossRef data.
        \item User-generated content (e.g., \texttt{note}, \texttt{file} fields) from all duplicates is merged into this golden record, upholding the principle to \textit{Preserve User Intent}.
        \item For entries that still lack a DOI, a secondary fuzzy-matching algorithm is used to find duplicates based on title and author similarity.
    \end{itemize}
    The output is a new file (e.g., \texttt{03\_reconciled.json}) containing a deduplicated list of golden records.

    \item \textbf{Phase 4: Triage and Reporting} \\
    The final phase categorizes each golden record and produces the final output. Each record is triaged as 'Verified', 'Accepted', or 'Suspect' based on a set of rules (e.g., an article without a DOI is 'Suspect'). This follows the \textit{Triage, Don't Discard} principle. The workflow concludes by writing the 'Verified' and 'Accepted' records to the main output file, and the 'Suspect' records to a separate file for human review.
\end{enumerate}

\subsection{Core Components (The Classes)}
The architecture is implemented using a set of classes, each with a single, clear responsibility.

\begin{description}
    \item[\texttt{Ingestor}] Responsible for finding, parsing, and tagging all entries from source \texttt{.bib} files.
    \item[\texttt{APIClient}] Handles all raw HTTP communication with an external API like CrossRef, managing sessions, headers, and retries.
    \item[\texttt{Validator}] Uses the \texttt{APIClient} to execute the validation logic, determining the canonical DOI and status for each record.
    \item[\texttt{Reconciler}] Contains the business logic for deduplication, both by DOI and fuzzy matching, and for merging user-specific metadata into golden records.
    \item[\texttt{Triage}] Applies the ruleset to classify each golden record as 'Verified', 'Accepted', or 'Suspect'.
    \item[\texttt{Writer}] Handles the final step of writing the categorized records to their respective output \texttt{.bib} files.
\end{description}

\subsection{Understanding the Output}
The final output consists of two main files and a console summary, ensuring full transparency.
\begin{itemize}[leftmargin=*]
    \item \textbf{Main Output File} (e.g., \texttt{cleaned\_library.bib}): Contains the high-confidence 'Verified' and 'Accepted' records.
    \item \textbf{Suspect File} (e.g., \texttt{suspect\_entries.bib}): Contains all 'Suspect' records that require manual human review.
    \item \textbf{Console Summary:} A report printed to the terminal detailing the number of files processed, duplicates removed, DOIs added, and the final count of entries in each category.
\end{itemize}

\end{document}
